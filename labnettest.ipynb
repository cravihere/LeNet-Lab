{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "Image Shape: (28, 28, 1)\n",
      "\n",
      "Training Set:   55000 samples\n",
      "Validation Set: 5000 samples\n",
      "Test Set:       10000 samples\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", reshape=False)\n",
    "X_train, y_train           = mnist.train.images, mnist.train.labels\n",
    "X_validation, y_validation = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test             = mnist.test.images, mnist.test.labels\n",
    "\n",
    "assert(len(X_train) == len(y_train))\n",
    "assert(len(X_validation) == len(y_validation))\n",
    "assert(len(X_test) == len(y_test))\n",
    "\n",
    "print()\n",
    "print(\"Image Shape: {}\".format(X_train[0].shape))\n",
    "print()\n",
    "print(\"Training Set:   {} samples\".format(len(X_train)))\n",
    "print(\"Validation Set: {} samples\".format(len(X_validation)))\n",
    "print(\"Test Set:       {} samples\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Image Shape: (32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Pad images with 0s\n",
    "X_train      = np.pad(X_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_validation = np.pad(X_validation, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_test       = np.pad(X_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "    \n",
    "print(\"Updated Image Shape: {}\".format(X_train[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAH0AAAB6CAYAAACShVydAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f48e66f898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # SOLUTION: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # SOLUTION: Layer 2: Convolutional. Output = 10x10x16.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # SOLUTION: Flatten. Input = 5x5x16. Output = 400.\n",
    "    fc0   = flatten(conv2)\n",
    "    \n",
    "    # SOLUTION: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "\n",
    "    # SOLUTION: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(84))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "\n",
    "    # SOLUTION: Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 10), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(10))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rate = 0.001\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits, one_hot_y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.964\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.980\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.983\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.985\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.982\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.989\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.990\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.990\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.988\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.990\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, 'lenet/')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.991\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'lenet/')\n",
    "\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
